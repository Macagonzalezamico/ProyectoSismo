{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping de la pagina Agencia Meteorologica de Japon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos todas las librerias necesarias para realizar el Web Scrapping\n",
    "\n",
    "import collections\n",
    "collections.Callable = collections.abc.Callable\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import schedule\n",
    "import ydata_profiling \n",
    "from ydata_profiling import ProfileReport\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la libreria Selenium, abriremos un navegador Chrome, en la pagina de los anuncios de Yapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome() #Cargamos el driver a una variable\n",
    "myUrl = \"https://www.data.jma.go.jp/multi/quake/?lang=es\" #Url de la pagina donde vamos a ingresar\n",
    "browser.get(myUrl) #Abrimos Chrome\n",
    "time.sleep(5)\n",
    "pageSoup = soup(browser.page_source, \"html.parser\") #Convertimos nuestro archivo a HTML.\n",
    "pages = pageSoup.find(\"table\", class_=\"quakeindex_table\") #Encontramos el tag y la clase que nos interesa obtener.\n",
    "links = pages.find_all(\"a\") #Encontramos el tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links #Revisamos que realizo la extraccion de los URL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los links actualizados y separados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_links = [] #Lista vacia para almacenar los links\n",
    "for indice, elemento in enumerate(links): #iteramos en los links\n",
    "    if \"quake\" in str(links[indice]): \n",
    "        inicio = str(links[indice]).index(\"quake\") #Extraemos el inicio del link\n",
    "        fin = str(links[indice]).index(\">\")-1 #extraemos el final del link\n",
    "        link = str(links[indice])[inicio:fin] #Obtenemos los links\n",
    "        link = str(link).replace(\"amp;\", \"\") #Reemplazamos para obtener el link limpio\n",
    "        lista_links.append(link) #Agregamos a la lista vacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_links #Revisamos que realizo la adiccion de los links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos la informacion necesaria por cada link y reemplazamos la informacion necesaria para que quede limpio e ingestarlo en nuestro Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la tabla donde ira la informacion\n",
    "df = pd.DataFrame(0, index=range(len(lista_links)),columns=[\"Hora y dia del Sismo\", \"Latitud\", \"Longitud\", \"Magnitud\", \"Profundidad del Hipocentro\", \"Lugar del Epicentro\"])\n",
    "\n",
    "seguir = 0\n",
    "comodin = 0\n",
    "while seguir != len(lista_links):\n",
    "    lista_links = [] #Lista vacia para almacenar los links\n",
    "    for indice, elemento in enumerate(links): #iteramos en los links\n",
    "        if \"quake\" in str(links[indice]): \n",
    "            inicio = str(links[indice]).index(\"quake\") #Extraemos el inicio del link\n",
    "            fin = str(links[indice]).index(\">\")-1 #extraemos el final del link\n",
    "            link = str(links[indice])[inicio:fin] #Obtenemos los links\n",
    "            link = str(link).replace(\"amp;\", \"\") #Reemplazamos para obtener el link limpio\n",
    "            lista_links.append(link) #Agregamos a la lista vacia\n",
    "    seguir += 1\n",
    "  \n",
    "    while comodin != len(lista_links):\n",
    "        datos = [] #Lista vacia para almacenar los datos de cada fecha\n",
    "        for indice in range(len(lista_links)): #iteramos sobre la lista de links\n",
    "            url_unico = \"https://www.data.jma.go.jp/multi/quake/\"+lista_links[indice] #concatenamos la informacionn de cada elemento con el url.\n",
    "            browser_2 = webdriver.Chrome() #Cargamos el driver a una variable\n",
    "            myUrl = url_unico #Url de Yapo para venta de celulares en la region metropolitana\n",
    "            browser_2.get(myUrl) #Abrimos Chrome\n",
    "            time.sleep(7) \n",
    "            pageSoup = soup(browser_2.page_source, \"html.parser\") #Convertimos nuestro archivo a HTML.\n",
    "            pages = pageSoup.find(\"table\", class_=\"quakeindex_table\") #Encontramos el tag y la clase que nos interesa obtener.\n",
    "            tr = pages.find_all(\"td\")  #Encontramos el tag.\n",
    "            datos.append(tr) #Agregamos a la lista vacia\n",
    "        \n",
    "            for indice, elemento in enumerate(datos): #iteramos para reemplazar las tags que trae del web scraping.\n",
    "                if len(datos[indice]) == 6:\n",
    "                    df[\"Hora y dia del Sismo\"][indice] = str(datos[indice][0]).replace(\"</td>\", \"\").replace(\"<td>\", \"\")\n",
    "                    df[\"Latitud\"][indice] = str(datos[indice][1]).replace(\"</td>\", \"\").replace(\"<td>\", \"\")\n",
    "                    df[\"Longitud\"][indice] = str(datos[indice][2]).replace(\"</td>\", \"\").replace(\"<td>\", \"\")\n",
    "                    df[\"Magnitud\"][indice] = str(datos[indice][3]).replace(\"</td>\", \"\").replace(\"<td>\", \"\")\n",
    "                    df[\"Profundidad del Hipocentro\"][indice] = str(datos[indice][4]).replace(\"</td>\", \"\").replace(\"<td>\", \"\")\n",
    "                    df[\"Lugar del Epicentro\"][indice] = str(datos[indice][5]).replace(\"</td>\", \"\").replace(\"<td>\", \"\")\n",
    "                else:\n",
    "                    print(indice, elemento)\n",
    "        comodin+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hora y dia del Sismo</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Magnitud</th>\n",
       "      <th>Profundidad del Hipocentro</th>\n",
       "      <th>Lugar del Epicentro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/06/30 00:48</td>\n",
       "      <td>36.5N</td>\n",
       "      <td>140.7E</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50km</td>\n",
       "      <td>Alta mar de Prefectura de Ibaraki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/06/29 22:20</td>\n",
       "      <td>24.8N</td>\n",
       "      <td>124.2E</td>\n",
       "      <td>3.8</td>\n",
       "      <td>80km</td>\n",
       "      <td>Mares cercanos de Isla Ishigaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023/06/29 20:01</td>\n",
       "      <td>28.4N</td>\n",
       "      <td>129.5E</td>\n",
       "      <td>3.1</td>\n",
       "      <td>30km</td>\n",
       "      <td>Mares cercanos de Islas de Amamioshima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023/06/29 02:27</td>\n",
       "      <td>35.0N</td>\n",
       "      <td>135.6E</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Poco profundo</td>\n",
       "      <td>Sur de Prefectura de Kioto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023/06/28 17:22</td>\n",
       "      <td>44.9N</td>\n",
       "      <td>142.1E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10km</td>\n",
       "      <td>Norte de regi√≥n Soya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2023/05/31 15:20</td>\n",
       "      <td>33.8N</td>\n",
       "      <td>135.0E</td>\n",
       "      <td>3.1</td>\n",
       "      <td>10km</td>\n",
       "      <td>Canal de Kii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2023/05/31 10:04</td>\n",
       "      <td>38.9N</td>\n",
       "      <td>142.0E</td>\n",
       "      <td>3.7</td>\n",
       "      <td>50km</td>\n",
       "      <td>Alta mar de Prefectura de Miyagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2023/05/31 07:49</td>\n",
       "      <td>33.4N</td>\n",
       "      <td>139.3E</td>\n",
       "      <td>4.3</td>\n",
       "      <td>10km</td>\n",
       "      <td>Mares cercanos de Isla de Hachijyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2023/05/31 04:06</td>\n",
       "      <td>36.0N</td>\n",
       "      <td>137.4E</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10km</td>\n",
       "      <td>Regi√≥n Hida, Prefectura de Gifu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2023/05/31 03:41</td>\n",
       "      <td>37.5N</td>\n",
       "      <td>137.3E</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10km</td>\n",
       "      <td>Regi√≥n Noto, Prefectura de Ishikawa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hora y dia del Sismo Latitud Longitud Magnitud Profundidad del Hipocentro  \\\n",
       "0       2023/06/30 00:48   36.5N   140.7E      4.0                       50km   \n",
       "1       2023/06/29 22:20   24.8N   124.2E      3.8                       80km   \n",
       "2       2023/06/29 20:01   28.4N   129.5E      3.1                       30km   \n",
       "3       2023/06/29 02:27   35.0N   135.6E      2.2              Poco profundo   \n",
       "4       2023/06/28 17:22   44.9N   142.1E      3.0                       10km   \n",
       "..                   ...     ...      ...      ...                        ...   \n",
       "163     2023/05/31 15:20   33.8N   135.0E      3.1                       10km   \n",
       "164     2023/05/31 10:04   38.9N   142.0E      3.7                       50km   \n",
       "165     2023/05/31 07:49   33.4N   139.3E      4.3                       10km   \n",
       "166     2023/05/31 04:06   36.0N   137.4E      2.8                       10km   \n",
       "167     2023/05/31 03:41   37.5N   137.3E      2.5                       10km   \n",
       "\n",
       "                        Lugar del Epicentro  \n",
       "0         Alta mar de Prefectura de Ibaraki  \n",
       "1           Mares cercanos de Isla Ishigaki  \n",
       "2    Mares cercanos de Islas de Amamioshima  \n",
       "3                Sur de Prefectura de Kioto  \n",
       "4                      Norte de regi√≥n Soya  \n",
       "..                                      ...  \n",
       "163                            Canal de Kii  \n",
       "164        Alta mar de Prefectura de Miyagi  \n",
       "165      Mares cercanos de Isla de Hachijyo  \n",
       "166         Regi√≥n Hida, Prefectura de Gifu  \n",
       "167     Regi√≥n Noto, Prefectura de Ishikawa  \n",
       "\n",
       "[168 rows x 6 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df#Verificamos que se haya scrapeado la info."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
